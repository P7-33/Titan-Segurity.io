---
title: 'A Typology of Organisational Cultures'
date: 2020-01-13T04:47:00+01:00
draft: false
---

![](https://qualitysafety.bmj.com/sites/default/files/highwire/default/covers/qhc-default-issue-cover_0.png "A typology of organisational cultures | BMJ Quality & Safety")  

A typology of organisational cultures is described, based on the medical unit’s style of information processing. A culture is defined as the organisation’s pattern of response to the problems and opportunities it encounters. Three dominant types—pathological, bureaucratic, and generative—are described. These types are shaped by the preoccupations of the unit’s leaders. The workforce then responds to these priorities, creating the culture. A focus on personal needs leads to a pathological environment, a focus on departmental turf to a bureaucratic style, and a focus on the mission to a generative style. These organisational types respond characteristically to signs of trouble and to opportunities for innovation. The value of a culture of conscious inquiry is illustrated through case studies. Although case studies supporting this scheme are plentiful, systematic tests of the hypothesis are harder to find. While some systematic studies demonstrate a relationship between medical outcomes and the three cultures, others fail to show it. None the less, it represents a unique approach to the problem of characterising the culture of medical units.

Culture shapes an organisation’s response to problems. Probably the most helpful insight is to see culture as that set of processes that shapes organisational response to the challenges that organisations face. It is useful to view organisations’ responses as forming coherent patterns. We might see culture for an organisation as analogous to personality in the individual. The differences in response patterns can be striking. For instance, political scientist Robert Putnam systematically compared the patterns of action of the newly formed regional governments of Italy. Each of these governments reflected the dominant culture of its region. Each of them had systematically different reactions even to simple matters such as responding to a letter from constituents.

“…We were gratified to discover…a surprisingly high consistency among our twelve diverse indicators of institutional performance. Regions that have stable cabinets, adopt their budgets on time, spend their appropriations as planned, and pioneer new legislation are, for the most part, the same regions that provide day care centers and family clinics, develop comprehensive urban planning, make loans to farmers, and answer their mail promptly.”[1](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-1)

Putnam found that culture involves the pattern of thought, emotion, and action. All of these are involved in shaping response to problems and opportunities. Culture, then, is the patterned way that an organisation responds to its challenges, whether these are explicit (for example a crisis) or implicit (a latent problem or opportunity). If this premise is accepted, obvious questions follow:

*   How can we classify cultures?
    
*   How do cultures develop?
    
*   How can these cultures be changed or improved?
    
*   What are their implications for patient safety?
    

In what follows we will try to answer these questions.

THE THREE CULTURES MODEL
------------------------

To speak of organisational culture is to take on many problems. Approaches to organisational culture have been diverse, and even with systems safety as a focus, there appears to be no common understanding about what culture is.[2](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-2) Does culture pertain to the whole organisation or also to its parts? How is culture different from climate? Can culture be measured by surveys of individuals, or must it be inferred from organisational behaviour? These questions are important, but addressing them would take us too far afield.

The most critical issue for organisational safety is the flow of information. I created a typology in 1988 to compare the way that organisations processed information.[3](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-3) This follows prior work regarding social intelligence on hidden events; for instance, response to the battered child syndrome.[4](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-4) The idea was to characterise general ways of coping with information, especially information that suggests anomaly. Failures in information flow figure prominently in many major accidents, but information flow is also a type marker for organisational culture. In some organisations, information flows well, and elicits prompt and appropriate responses. In others it is hoarded for political reasons or it languishes due to bureaucratic barriers. This typology has proven useful in a variety of safety related fields, such as aviation, nuclear power, and, increasingly, medicine. Although the typology is not a direct measure of safety culture, it appears to relate strongly to safety. While many practitioners (such as the US Air Line Pilots Association) find the typology intuitive and easy to use, its details are still being worked out.

The underlying idea is that leaders, by their preoccupations, shape a unit’s culture. Through their symbolic actions, as well as rewards and punishments, leaders communicate what they feel is important. These preferences then become the preoccupation of the organisation’s workforce, because rewards, punishments, and resources follow the leader’s preferences. Those who align with the preferences will be rewarded, and those who do not will be set aside. Most long time organisation members instinctively know how to read the signs of the times and those who do not soon get expensive lessons.

I would identify three typical patterns. The first is a preoccupation with personal power, needs, and glory. The second is a preoccupation with rules, positions, and departmental turf. The third is a concentration on the mission itself, as opposed to a concentration on persons or positions. I call these, respectively, pathological, bureaucratic, and generative patterns. These preferences create recognisable climates that affect the processing of information and other cognitive activities. The climate shapes activities such as communication, cooperation, innovation, and problem solving. Although this correlation is a hypothesis, it is based on considerable observation and study. The reasons for this correlation are still being explored. The typology is shown in table 1.

**Table 1**

 How organisations process information

The scheme concentrates on information flow as a key variable. Information flow includes not only how much information flows from point A to point B, but its relevance, timeliness, and appropriateness to the recipient. Generative organisations get the needed information to the right person in the right form and in the right time frame. This behaviour is based on the leader’s emphasis that the most important goal is to accomplish the mission. So, the key that guides communication behaviour is “who needs the information now?” Generative organisations tend to be proactive in getting the information to the right people by any means necessary.[5](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-5)

By contrast, pathological circles tend to view information as a personal resource, to be used in political power struggles. It will be withheld, doled out, or used as a weapon to advance particular parties within the organisation. Robert Daley’s novel, _Man with a gun_, begins with a high level meeting at police headquarters in New York.[6](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-6) The book notes that although the ostensible purpose of the meeting is to solve some problems with police patrols, the real purpose of the meeting is to embarrass the chief of patrol and get him to resign. Such devious use of information is typical of pathological organisations. In 2003, when the Chief Actuary of the American Medicare Program developed budget estimates that disturbed the administration, his Bureau Chief, Tom Scully, told him to keep quiet about them or he would “fire him so fast his head would spin.”[7](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-7) Other examples come readily to mind.

Patterns in information handling thus reflect the climate. If leaders emphasise that information is to help accomplish the mission, that use will predominate. If leaders emphasise that information must advance departmental goals, then that behaviour will predominate. If leaders show through their behaviour that information is only important as it advances or impedes their personal interests, then that use will predominate.

When bureaucratic organisations need to get information to the right recipient, they are likely to use the standard channels or procedures. These standard channels and procedures are often insufficient in a crisis. They failed, for instance, in communications between New York police and fire departments on 11 September 2001. The police knew that the World Trade Center north tower was about to collapse, but failed to communicate this to the firefighters inside the tower, many of whom died.[8](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-8) By contrast, in the same circumstances many generative organisations would cross departmental lines or use a back channel to get the information to where it was needed. The Apollo 13 space crisis shows an excellent example of a generative response.[9](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-9) By contrast, the fumbling that led to the demise of Columbia space shuttle shows bureaucracy at its worst.[10](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-10)

Again, the climate that provides good information flow is likely to support and encourage other kinds of cooperative and mission enhancing behaviour, such as problem solving, innovation, and inter-departmental bridging. When things go wrong, pathological climates encourage finding a scapegoat, bureaucratic organisations seek justice, and the generative organisation tries to discover the basic problems with the system. The effects of information flow climate are pervasive. And they are pervasive because the climate shapes three key variables: alignment, awareness, and empowerment.

In a generative organisation alignment takes place through identification with the mission. The individual “buys into” what he or she is supposed to do and its effect on the outcome. A sense of ownership is a natural consequence of identification with the leaders and the team. Accordingly this person will try harder for and care more about the outcome. By contrast, in a bureaucratic organisation alignment with the person’s own unit or function takes the place of alignment with the mission. The department’s interest will be fought for without regard for its effect on the mission. In pathological organisations, alignment is typically with a person or a clique, whose interests are advanced in preference to other loyalties. Robert Gallo’s sparring with French researcher Luc Montagnier over the nature of AIDS shows how personal needs can interfere with solving a key social problem.[11](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-11)

Awareness comes when there are conscious efforts to keep team members informed about all the variables that affect their efforts. These efforts are most strenuous in generative organisations. Instead of working in the dark regarding issues that have a material bearing on what they are doing, team members are put in the picture about what is happening and why. They have a grasp of the larger situation. This awareness also means they are likely to take more factors and more needs of others into account, showing what Roberts and Weick call heedful interaction.[12](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-12) By contrast, awareness is necessarily constricted by personal or departmental function in bureaucratic organisations. When technicians working on the Hubble Space Telescope jury-rigged the critical measuring rod, they did not realise they were causing a multi-billion dollar problem.[13](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-13) In pathological organisations, the implications for power struggles are the focus of awareness.

Empowerment also shows very different patterns for the three cultures. Generative organisations require empowerment for maximum performance. Individuals’ minds are harnessed to fulfill the organisation’s goals through a culture of conscious inquiry. They are encouraged to speak up, think outside the box, and to act as fully conscious participants in a great cooperative enterprise. In bureaucratic organisations, however, thinking may stop at the department’s boundary because what is beyond it is “not my concern”, even though it may be of great concern to the mission. The ability to think is often coextensive with the ability to act. When the space shuttle Columbia’s managers felt they could do nothing to save the spaceship if it was damaged, they made few efforts to get in-flight photographs, and even interfered with those who were desperately seeking them.[14](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-14) Similarly, radiologists who early became aware of battered children often did little with the information they got because they had little influence beyond the hospital.[15](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-15)

Although information flow is a shaping influence, this does not always mean that the organisation with better information flow is always more creative, more harmonious, or more safe. Information flow helps the organisation achieve its goals—whatever they are. Safety may or may not be the paramount value. Yet on the whole, generative organisations (those with good information flow) are probably more creative, more harmonious, and safer. The reason is simple: the kind of conditions that create good information flow tend to be those that favour cooperation, creativity, and safety. On the other side, conditions that interfere with information flow also tend to decrease creativity, create conflict, and make the organisation involved less safe.

The scheme captures only a portion of organisational culture. There are many issues on which the model is silent, such as training, structure, and styles of problem solving, to take only a few. Furthermore, the relationship between climate and performance is statistical, not deterministic. There are many organisations that are effective but are not generative, and whose performance is based on other features, such as a brilliant algorithm or a charismatic leader. With these restrictions in mind, it is correct to call this typology one of organisational culture.

CASE STUDY EVIDENCE
-------------------

A mass of case study and anecdotal evidence suggests that generative environments, with high alignment, awareness, and empowerment, are more effective than the alternatives. A fine example from the military is the creation of a generative environment aboard the USS _Benfold_, a destroyer. Through a remarkable programme to encourage cross training, participation, and creativity, Commander Michael Abrashoff created a floating palace of creativity. The USS _Benfold_ became the most battle ready ship in the Pacific Fleet, an achievement recognised through its receipt of the Spokane Trophy in 1999. It was also the most sought after billet for sailors, and highly efficient financially.[16](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-16) Commercial examples of generative organisations, such as 3M, Southwest Airlines, and Chaparral Steel, are well known, yet the dynamics of their creativity have yet to be fully explored. The author has carried out one parallel exploration through his analysis of the dynamics of a famous naval research and development facility, China Lake.[17](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-17) From these and other examples, there would seem little question that creativity and generative information flow usually go together.

For instance, the study of China Lake, a highly generative organisation, showed several remarkable features. The organisation consistently performed beyond ordinary expectations, often putting to shame other organisations’ efforts (the Sidewinder missile was a key example). The organisation had high flexibility, and seemed to be excellent both in using its own experience and other organisations’ experiences as well. A “community of good judgment” carefully kept track of credentials and apprenticeships, and tried to match people with jobs. Unusual latitude was given to individuals to develop their own ideas, including the bootlegging of monies from more routine projects to those that involved greater creativity. Both internal management and higher naval sponsorship supported projects well beyond the organisation’s charter, including an early space satellite programme that has been kept out of official histories and a submarine programme developed at this desert base!

But how about safety? Are generative environments really more safe? And if so, why? Certainly the processes associated with fixing the hidden problems that Reason has called latent pathogens would seem strongly connected with information flow; detection, reporting, problem solving, and implementation.[18](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-18) The response of the USS _Benfold_ to a dangerous fuel leak was to suggest fixing the problem across the squadron, a solution that some other captains thought was unnecessary.[19](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-19) This is typical. Southwest Airlines, certainly a generative airline, also has an excellent safety record. One of the reasons for this is a suggestion and reporting system that is strongly supported by a company culture with high empowerment.[20](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-20)

The connection between organisational culture and information processing is that better organisation culture leads to better processing. The fact that becomes a political football for the pathological organisation, or is simply ignored by the bureaucratic one, is used effectively by the generative organisation. This is even more evident if we classify responses to signals that things are amiss. I have suggested that response to anomaly—that is, to potential indicators of latent pathogens—might be classified in six types: suppression, encapsulation, public relations, local fix, global fix, and inquiry (see fig 1).

**Figure 1**

 Response to anomaly.

For instance, in aviation, discoveries of a particular structural problem in one aircraft often lead to checking other aircraft of the same type, thus surfacing unsuspected problems and leading to a global fix. Failure to address the problem across the board may have fatal results. A crash of an ATR-72 airliner in Italy, for instance, was carefully written up to avoid finger pointing, thanks to heavy pressure from the French aviation industry. The crash did not lead to a worldwide alert that the aircraft might have a mode, under certain conditions, that would lead to one of the wings dipping suddenly, and thus causing loss of lift. The failure to engage a global fix may have led to a second ATR-72 that crashed in Roselawn, Illinois.[21](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-21) The encapsulation of the facts by the original accident report had a devastating result.

One of the most important features of a culture of conscious inquiry is that what is known in one part of the system is communicated to the rest. This communication, necessary for a global fix, aids learning from experience, very important in systems safety. The communication occurs because those in the system consider it their duty to inform the others of the potential danger or the potential improvement. Edmondson, by contrast, found that in several hospitals the local fix or workaround did not result in the system as a whole taking note, because channels to convey the problem were absent, invisible, or took too much time to use.[22](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-22) It may be readily appreciated that the qualities of the culture as a whole thus affect response to anomaly.

These responses are related to the cultural types. In particular, suppression appears to be a type marker for pathological environments. Inquiry and global fixes, meanwhile, are strongly associated with generative environments. Bureaucracies, however, prefer to use the other strategies. If these associations are correct, there are important implications for safety. Pathological environments will discourage taking responsibility, and can be expected to conceal their problems. In contrast, generative environments are more likely to surface, and to fix, latent pathogens. They are more likely to encourage error talk and organisational learning via inquiry.

An interesting example of this surfacing and inquiring is one hospital’s response to the discovery in 1999 that two of its pathologists had made 20 wrong prostrate biopsy diagnoses. The hospital was Sturdy Memorial Hospital in Attleboro, Massachusetts. A urologist had discovered the problem when one of his patients was diagnosed with prostrate cancer yet had had a negative biopsy. After a second similar example, suspicions were raised about biopsy standards. The hospital then carried out an internal audit of 279 prostate biopsies done over 2 years, which showed 20 of them to be in error. Rather than attempting to cover up the situation, or downplay it, Sturdy announced it would hire consultants to audit some 6000 additional biopsies. The hospital reported the biopsy problems to state authorities, sent regular updates to its staff, and wrote 88 000 letters to hospital patients explaining the situation. The response was very positive from the regulators and the public:

“Throughout this process, there was no measurable negative impact on the hospital’s workload or financial performance. Nor were the urologists adversely affected. Our openness reaffirmed our reputation for putting our patients first. Our patients were much more accepting of the inevitability of human error than we were, and they were impressed that we were doing something about it. Our experience suggests that putting patients first is also a good business strategy when addressing errors.”[23](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-23)

This example of the inquiry response is notable and unusual. In stark contrast is the behaviour of the Canadian blood authorities to suspicions in the early 1980s that the national blood supply might be contaminated with HIV and hepatitis. As the Krever Report has shown, instead, doubts were muted, critics were muzzled, response was slow, and the public was misled.[24](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-24) For instance, over 1000 transfusion deaths and an even larger number of HIV infections of haemophiliacs resulted, an appalling toll. While epidemiologists were discussing the potentially compromised blood supply, haemophiliacs were being told that blood fractions they used were safe. Supplies of potentially contaminated blood were still being distributed even after supplies that had been successfully heat treated were available. In other words, encapsulation, public relations, and local fixes were the preferred responses to the anomaly represented by suspicions of HIV and hepatitis C contamination. Canada was far from unique in its response to HIV blood problems, but should have been much further ahead of the game than it was: it had had a full year to study the Americans’ problems. The institutions it used to manage the blood supply, however, could not change their bureaucratic ways so they could respond appropriately. Using these bureaucratic forms of anomaly response led to widespread contamination, infection, and death.

A STRIKING CONFIRMATION
-----------------------

Although using concepts to describe problems is useful, what assurance do we have that we are not simply adding new labels to events already understood? There are many cases where the concept seems to fit well, yet even though such case study evidence is abundant, systematic tests of this typology are rare. A most striking confirmation of the validity is Edmondson’s comparison of nursing supervision styles in eight different hospital departments.[25](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-25) This study appeared to demonstrate that information flow is higher in a generative situation, where managers see themselves as coaches rather than commanders.

Although Edmondson’s study was not designed to test the typology, the patterns discovered by Edmondson are those predicted by the model. The nursing supervisors who encouraged a free and open environment had information flow (that is, error reporting) very much above those who chose hierarchy as more important. In fact there is a 10-fold difference in the best and the worst cases.

If we take Edmondson’s results at face value, the impact of nursing supervision on information flow environment would seem strong. What if one department actually caught 10 times more errors than another? What is more likely, however, is that many errors get fixed without being reported. Those that are reported are a percentage of those that take place, a percentage that may vary with the cultural quality of the environment. So Edmondson’s numbers are suggestive, not definitive. Still, the increased visibility of problems would allow the unit to work on them better, and this is a great gain in itself.

Edmondson’s study provides a striking confirmation, in a medical context, of the value of this scheme. There still remains, meanwhile, the link between these information flow patterns and medical outcomes. Information flow would seem to be strongly related to safety, but while we may infer that information flow creates safety, proof is scarce. A promising study in 1986 suggested that cooperation in intensive care units led to lower patient mortality, but a follow up study did not support this conclusion.[26](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-26) If culture makes a difference, it should not be so hard to detect. On the other hand, another study by Edmondson _et al_ about the culture of minimally invasive cardiac surgery (MICS) surgery teams strongly supports the generative model as against a bureaucratic model in terms of a team’s success in adopting novel techniques. The teams that encouraged information flow were more successful in institutionalising MICS surgery in their respective hospitals.[27,](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-27)[28](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-28)

ORIGINS AND DYNAMICS
--------------------

One might wonder how such cultures develop and change. The role of leadership in creating such environments would appear large from books, such as that of Abrashoff Edmondson _et al_’s study of the diffusion of MICS techniques, which also shows strong differences in adoption success, based on surgical leadership. The successful surgical teams seem to adopt a culture of conscious inquiry, with selective recruitment, open discussion, pre-operation briefings, and a levelling of status differences.[29](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-29) My own impression is that the role of leadership is most evident at the extremes, and less evident for bureaucratic cultures. Bureaucratic culture (as distinct from the bureaucracies themselves) appears as a kind of default value, rather like the centre of a normal distribution. This is not to say that there are not bureaucratic leaders; it is rather that bureaucracy is often a compromise between competing interests.

How does one culture change into another? The easy answer is that a change in leaders will often precipitate such changes, as for instance Abrashoff’s success on the USS _Benfold_ suggests. For a portrait of the creation of a pathological environment, consider the deleterious influence of Arthur Holland on the culture of Fairchild Air Force Base.[30](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-30) Holland, a rogue B-52 pilot, routinely ignored regulations and exposed his aircraft and crew to extreme danger. But he was admired by his commanding officers, so his extreme actions provoked only mild sanctions and instead got emulation from other would be rogues. Only his suicidal crash in a B-52 ended his influence on the base and led to investigations. It is also possible that the leaders of an organisation can consciously decide to maintain a particular type of culture, to attract top practitioners. Meanwhile, studying the dynamics of climate building in the medical universe has just begun. This would be a fruitful direction for future research.

DISCUSSION
----------

Although one off studies of medical safety culture have value, the true need is for a scheme that captures one or a few dimensions in an easy to understand way.[31](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-31) Dimensions ought to be clear enough so that individuals can locate their organisations on them. Otherwise, culture becomes an arcane matter that can only be measured by questionnaire. It is true that some questionnaires that measure personality features or sets of attitudes may be valuable in assessing culture, such as the Flight Management Attitudes Questionnaire used by Helmreich and others.[32](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-32) By measuring the attitudes of an organisational workforce we can gain insights of some important aspects of culture. However, culture shapes action in many important areas, from everyday operations to innovation, and provides important clues as to how things may go wrong.[33](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-33) Even the kind of latent pathogens that one encounters are a function of the organisation’s culture.[34](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-34)

The process by which the leader’s preoccupations are translated into workforce culture is well described by Abrashoff. Once set in motion, a unit’s climate has a powerful ability to affect outcomes. This is largely due to pervasive effects of information flow, whose problems have been implicated in so many accidents. Abrashoff managed to change the culture of the _Benfold_ in only a few months. On the other hand, the regional cultures described by Putnam have been in place for centuries. A ship, although part of a fleet, is an isolated unit. A regional or national culture, by contrast, is likely to remain unchanged over long periods of time. For this reason, we should not neglect the role of the larger environment. Every medical unit is part of something larger; a hospital, a clinic, an health maintenance organisation. How does the climate of this larger organisation affect that of the unit in question? Does the isolated generative unit become a “Cinderella”, the target of hostile jibes and political actions? This certainly happened to the high performing naval laboratory I studied. A study of emergency department team training stressed the need to consider the larger context.[35](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#ref-35) Does the isolated pathological culture get fixed, or does it contaminate the larger environment? Often pathological units can get away with horrid performances if they have the right political connections, are good at securing grants, or have a high publication rate. In many hospitals, it is notorious that some units and some individuals, because of elite status, can get away with anything. So the context matters.

CONCLUSION
----------

Culture in a medical unit, then, is typically shaped by the preoccupations of the management. These preoccupations and priorities are absorbed by the workforce, who then operate with them in mind. Information will flow, or not. Issues will be addressed, or not. Because most medical work involves teams, information will provide the glue that keeps the team focused and coordinated. If the glue is weak, so will the team be. The culture, then, represents those habits of thought and action by changing the culture, virtually everything can change—trust, openness, confidence, and even competence. A generative culture will make the best use of its assets, a pathological one will not. This is what the theory predicts, and what the case studies show. But it still remains to be determined whether culture has systematic impacts along the lines we have sketched on a broader scale. If it does, then we need to pay more attention to the forces shaping the culture of our medical teams and medical organisations. We need the benefits and relative immunity that a good human envelope implies.

### **Implications for clinical practice**

*   Leadership in the medical unit shapes the culture, which shapes the information flow.
    
*   Good information flow and processing has important effects on patient safety.
    
*   In particular, an open and generative culture will mean better uptake of innovations and better response to danger signals.
    
*   A generative culture requires that alignment, awareness, and empowerment replace suspicion, isolation, and passivity.
    
*   A culture of conscious inquiry will assist in getting fundamental improvements to the system, rather than just quick fixes.
    

### **Key messages**

*   To be able to work with and understand organisational culture, we need a typology of organisational environments.
    
*   Information processing style is a useful focus for such a typology, because information is important directly and is correlated with other features of the organisation’s culture.
    
*   Three typical styles of information processing are pathological, bureaucratic, and generative.
    
*   These styles are shaped by leaders’ preoccupations, including focus on personal needs, bureaucratic objectives, and the organisation’s mission.
    
*   These styles are associated with different responses to signs of trouble and opportunities for innovation.
    
*   Culture is mutable. With new leadership, an environment with one kind of culture can change into another.
    

Acknowledgments
---------------

The author gratefully acknowledges the contributions of A Edmondson, H Kaplan, K Sutherland, and R Wears to an early version of this paper.

REFERENCES
----------

1.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-1-1 "View reference 1 in text")
    
    **Putnam R**. Making democracy work: civic traditions in modern Italy. Princeton, NJ: Princeton University Press, 1993:74.
    
2.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-2-1 "View reference 2 in text")
    
    **Westrum R**, Adamski A. Organizational factors associated with safety and mission success in aviation environments. In: Garland DJ, Wise JA, Hopkins VD, eds. Aviation human factors. Hillsdale, NJ: Lawrence Erlbaum, 1999.
    
3.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-3-1 "View reference 3 in text")
    
    **Westrum R**. Organizational and interorganizational thought. Presentation to World Bank conference on Systems Safety 1988; (Available from the author upon request.).
    
4.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-4-1 "View reference 4 in text")
    
    **Westrum R**. Social intelligence about hidden events: its significance for science and social policy. Knowledge, Creation, Diffusion, Utilization1982;3:381–400.
    
5.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-5-1 "View reference 5 in text")
    
    **Guest RH**. Organizational change: the effect of successful leadership. Homewood, IL: Dorsey Press, 1962:90–1.
    
6.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-6-1 "View reference 6 in text")
    
    **Daley R**. Man with a gun. New York: Simon and Schuster, 1988.
    
7.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-7-1 "View reference 7 in text")
    
    **Pear R**. Medicare official claims intimidation over cost estimates. New York Times2004;14 March: 1, 22,.
    
8.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-8-1 "View reference 8 in text")
    
    **Dwyer J**, Flynn K, Fessenden F. 9/11 exposed deadly flaws in rescue plan. New York Times2002;7 July: 1, 10, 11,.
    
9.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-9-1 "View reference 9 in text")
    
    **Kranz E**. Failure is not an option: mission control from mercury to apollo 13 and beyond. New York: Simon and Schuster, 2000.
    
10.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-10-1 "View reference 10 in text")
    
    **Columbia Accident Investigation Board**. Report Vol. I. Washington DC: Government Printing Office, 2003.
    
11.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-11-1 "View reference 11 in text")
    
    **Shilts R**. And the band played on: politics, people and the aids epidemic. New York: St Martins, 1987.
    
12.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-12-1 "View reference 12 in text")
    
    **Roberts K**, Weick K. Collective mind and organizational reliability: The case of flight operations on an aircraft carrier deck. Administrative Science Quarterly1993;38:357–81.
    
13.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-13-1 "View reference 13 in text")
    
    **Lerner E**. What happened to Hubble? Aerospace AmericaFebruary 1991;:22.
    
14.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-14-1 "View reference 14 in text")
    
    **Cabbage M**, Harwood W. Comm check: the final flight of shuttle Columbia. New York: Free Press, 2004:254–5.
    
15.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-15-1 "View reference 15 in text")
    
    **Westrum R**. Thinking by groups, organizations and networks: a sociologist’s view of the social psychology of science and technology. In: Gholson B, Shadish WR, Neimeyer RA, eds, _et al_. Psychology of science: contributions to metascience. Cambridge: Cambridge University Press, 1989:329–42.
    
16.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-16-1 "View reference 16 in text")
    
    **Abrashoff M**. It’s your ship: management lessons from the best damn ship in the navy. New York: Warner Books, 2002.
    
17.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-17-1 "View reference 17 in text")
    
    **Westrum R**._Sidewinder:__creative missile design at china lake_. Annapolis, MD: Naval Institute Press, 1999.
    
18.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-18-1 "View reference 18 in text")
    
    **Reason J**. Human error. Cambridge: Cambridge University Press, 1990.
    
19.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-19-1 "View reference 19 in text")
    
    **Abrashoff M**. It’s your ship: management lessons from the best damn ship in the navy. New York: Warner Books, 2002:70.
    
20.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-20-1 "View reference 20 in text")
    
    **Montague T**. Southwest airlines turns 30. Southwest airlines spiritJune 2001;:58–69.
    
21.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-21-1 "View reference 21 in text")
    
    **Fredrick SA**. Unheeded warnings: the inside story of american eagle flight 4184. New York: McGraw-Hill, 1996.
    
22.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-22-1 "View reference 22 in text")
    
    **Tucker AL**, Edmondson AC. Why hospitals don’t learn from failures: Organizational and psychological dynamics that inhibit system change. California Management Review2003;45:55–72.
    
23.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-23-1 "View reference 23 in text")
    
    **Pietro DA**, Shyavitz LJ, Smith RA, _et al._ Detecting and reporting medical errors: why the dilemma? BMJ 2000;320:7946.
    
24.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-24-1 "View reference 24 in text")
    
    **Krever H**._Commission of inquiry on the blood system of Canada_, 3 vols. Ottawa: Canadian Government Publishing, 1997.
    
25.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-25-1 "View reference 25 in text")
    
    **Edmondson AC**. Learning from mistakes is easier said than done: group and organizational influences on the detection and correction of human error. Journal of Applied Behavioural Science1996;32:5–28.
    
26.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-26-1 "View reference 26 in text")
    
    **Knaus WA**, Draper EA, Wagner DP, _et al._ An evaluation of outcomes from intensive care in major medical centers. Annals of Internal Medicine 1986;104:410–418.
    
27.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-27-1 "View reference 27 in text")
    
    **Shortell SM**, Zimmerman JE, Rousseau DM, _et al._ The performance of intensive care units: does good management make a difference? Med Care 1994;32:508–25.
    
28.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-28-1 "View reference 28 in text")
    
    **Edmondson AC**. Speaking up in the operating room: how team leaders promote learning in interdisciplinary action teams. Journal of Management Studies2003;40 (6) :1419–52.
    
29.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-29-1 "View reference 29 in text")
    
    **Edmondson AC**, Bohmer RM, Pisano GP. Disrupted routines: team learning and new technology implementation in hospitals. Administrative Science Quarterly2001;46:685–716.
    
30.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-30-1 "View reference 30 in text")
    
    **Kern T**. Darker shades of blue: the rogue pilot. New York: McGraw-Hill, 1999:29–52.
    
31.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-31-1 "View reference 31 in text")
    
    **Pronovost PJ**, Weast B, Holzmueller CG, _et al._ Evaluations of the culture of safety: survey of clinicians and managers in an academic medical center. Qual Saf Health Care 2003;12:405–410.
    
32.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-32-1 "View reference 32 in text")
    
    **Helmreich R**, Merritt A. Culture at work in aviation and medicine. Aldershot: Ashgate, 1998.
    
33.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-33-1 "View reference 33 in text")
    
    **Westrum R**. Models of bureaucratic failure. In: Edkins G, Pfister P, eds. Innovation and Consolidation in Aviation. Aldershot: Ashgate, 2003:31–7.
    
34.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-34-1 "View reference 34 in text")
    
    **Westrum R**. The removal of latent pathogens. Australian Aviation Psychologists’ Symposium, Sydney, Australia, December 2003.
    
35.  [↵](https://qualitysafety.bmj.com/content/13/suppl_2/ii22#xref-ref-35-1 "View reference 35 in text")
    
    **Morey JC**, Simon R, Jay GD, _et al._ Error reduction and performance improvement in the emergency department through formal teamwork training: evaluation results of the MedTeams project. Health Services Research 2002;37:1553–81.
    

  
  
from Hacker News https://ift.tt/2qm3noE